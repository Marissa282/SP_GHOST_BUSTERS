---
title: "Situación problema: Ghostbusters!"
author:
  - Marissa Luna
  - Ximena Cantón
  - Mariana León
  - Nubia Garcidueñas
format:
   html:
     toc: true
     html-math-method: katex
     embed-resources: true 
     self-contained-math: true
     df-print: kable
editor: source
---

```{r}
library(robotstxt)
library(tidyverse)
library(stringr)
library(tidytext)
library(knitr)
library(ggplot2)
library(dplyr)
library(caret)
```

# WEB SCRAPING 
*✏️ Utilicen la función paths_allowed() del paquete robotstxt para comprobar que el web scraping está permitido en esta página.*

```{r}
paths_allowed("https://www.yourghoststories.com")
```
El web scarping está permitido. El proceso de cómo se realizó se encuentra dentro del repositorio en el archivo webbb.qmd. 

# LIMPIEZA
Antes de realizar el análisis de palabras, se limipió el archivo csv generado por el web scraping.  

```{r}
stories = read_csv("data/stories_final.csv") 
```

```{r}
#no. de filas antes de la limpieza
nrow(stories)
```

```{r}

stories = stories |>
  drop_na() |>                             #quitamos NA 
  filter(if_all(everything(), ~ .x != ""))  |> #quitamos vacíos 
  distinct() #quitamos duplicados
```

```{r}
#no. de filas después de la limpieza
nrow(stories)

#suma de NA y ""
sum(is.na(stories$description))
sum(stories$description == "")
```

# ANÁLISIS DE PALABRAS
*✏️ Realicen un pequeño análisis de texto utilizando la base de datos que scrapearon. La actividad de Mine sobre text mining les puede dar ideas y el código necesario para realizar este análisis.*

```{r}
#quitamos párrafos que no son parte de los relatos 
stories <- stories |>
  mutate(description = str_remove(description, "^You are here:.*?::\\s*"))  |>
  mutate(description = str_remove(description, "(?s)The following comments are submitted by users of this site.*$"))
```

```{r}
#Ver las primera historia para verificar borrado
stories$description[1:1]
```

```{r}
#Tokenizar
stories_words <- stories |>
  unnest_tokens(output = word, input = description)
```

```{r}
#Limpiar palabras
stories_clean = stories_words |>
  anti_join(stop_words, by = "word")  |> #quitamos stop words
  filter(!str_detect(word, "[0-9]")) #quito todo lo que tenga un número
```

```{r}
#Frecuencia global de palabras
frecuencia_global = stories_clean |>
  count(word, sort = TRUE)

#Gráfica con palabras más frecuentes
frecuencia_global |>
  slice_head(n = 30) |>
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(title = "Top palabras más frecuentes",
       x = "Palabra", y = "Frecuencia")
```

```{r}
# Frecuencia por relato
frecuencia_por_relato = stories_clean |>
  count(title, word, sort = TRUE)

# Para cada relato, top 5 palabras
top_por_relato = frecuencia_por_relato |>
  group_by(title)  |>
  slice_head(n = 5)  |>
  ungroup()

# Tabla de top palabras por relato
top_por_relato |>
  arrange(title, desc(n)) |>
  head(10) |>
  knitr::kable()
```

```{r}
titles_to_plot = top_por_relato  |>
  distinct(title)  |>
  slice_head(n = 9)  |> #no. de relatos en la gráfica
  pull(title)

p = top_por_relato  |>
  filter(title %in% titles_to_plot)  |>
  mutate(word = reorder_within(word, n, title))  |>
  ggplot(aes(x = n, y = word, fill = title)) +   #un color por gráfico
  geom_col(show.legend = FALSE) +
  facet_wrap(~ title, scales = "free_y") +
  scale_y_reordered() +
  scale_fill_brewer(palette = "Set3") + #paleta de colores
  labs(title = "Top 5 palabras por relato",
       x = "Frecuencia", y = NULL) +
  theme_minimal(base_size = 10) +
  theme(strip.text = element_text(face = "bold"),
        panel.spacing = unit(0.1, "lines"))

print(p)

```

Gracias al análisis de palabras determinamos que era necesario eliminar palabras que fueran stop words (nexos, preposiciones, pronombres, etc.) o que contuvieran números. Posteriormente, se filtraron aquellas palabras que se repitieran al menos 5 veces globalmente; ésto para eliminar ruido (tipo outliers) de nuestro clasificador. 

```{r}
#Utilizamos únicamete las palabras que se repiten al menos 5 veces globalmente
stories_clean = stories_clean  |>
  add_count(word, name = "tot")  |>
  filter(tot >= 5)  |>   # hacemos columna para filtro
  select(-tot)           # ocultamos la columna
```

# SPARSE MATRIX

```{r}
library(Matrix)    # matriz dispersa
library(e1071)     # naiveBayes sencillo
library(naivebayes) # naiveBayes 
```

*✏️ Construyan una sparse matrix que incluya la frecuencia de cada palabra en los relatos scrapeados, donde cada renglón representa un relato diferente y donde las columnas son las diferentes palabras. Esta matriz también debe contener el tipo de evento paranormal. La función unnest_tokens() les puede ayudar. Consideren eliminar las palabras comunes en inglés a través de las stop words. Todo este proceso se conoce como un count vectorizer, que significa transformar texto a vectores.*

```{r}
#matriz X, donde filas = títulos, columnas = palabras, valores = frecuencias
X = stories_clean |>
  count(title, word) |>
  cast_sparse(title, word, n) #sparse matrix

#vector y multiclase 
meta = stories|> distinct(title, paranormal_type) #title y su cat
y = meta$paranormal_type[ match(rownames(X), meta$title) ] #match entre titles que devuelve la cat correcta

stopifnot(length(y) == nrow(X)) #verificamos que y y x tengan misma longitud 
```

```{r}
#Visualizamos X en df para revisar que todo esté en orden
# Pasar rownames a columna llamada "doc_id"
X_df <- as.data.frame(as.matrix(X))
X_df <- tibble::rownames_to_column(X_df, var = "doc_id")

# Ver primeras filas
head(X_df, 10)
```
Estamos usando un formato de sparse matrix que no necesita tanta memoria. Para visualizar que la conversión haya sido la desada, convertimos a formato de data frame y verificamos que todo estuviera de manera adecuada. 

# Y MULTICLASE
*✏️ Dividan la matriz de datos en training y test set. Y utilicen el training set para entrenar un clasificador naïve Bayes para predecir el tipo de evento paranormal.*

```{r}
y = factor(y)
```

```{r}
#partición de X, y 
#utlizamos proporción 80/20
set.seed(123)
idx_train = createDataPartition(y, p = 0.80, list = FALSE)
idx_train = as.vector(idx_train)     # que sea vector, no matriz
idx_test  = setdiff(seq_len(nrow(X)), idx_train)

X_train = X[idx_train, , drop = FALSE]
X_test = X[idx_test,  , drop = FALSE]
y_train = y[idx_train]
y_test = y[idx_test]
```


## e1071
```{r}
#entrenamos naive bayes 
X_train = as.matrix(X_train) #pasamos a matriz densa (necesario para e1017)
mod_nb_multi = naiveBayes(x = X_train, y = y_train)
```

```{r}
#testeamos modelo
X_test = as.matrix(X_test)   #convertimos a matriz densa 
pred_test = predict(mod_nb_multi, X_test)
```

*✏️ Reporten la accuracy, precision, recall, F1-score y matriz de confusión con sus respectivas interpretaciones.*

```{r}
# mismos niveles para métricas
pred_test = factor(pred_test, levels = levels(y_train))
y_test = factor(y_test,    levels = levels(y_train))

cm = confusionMatrix(pred_test, y_test)
```

## naive_bayes()
*✏️ Intenten utilizar la función naive_bayes() del paquete naivebayes para volver a ajustar su clasificador, ¿existe alguna diferencia?*

```{r}
#entrenamos naive_bayes()
mod_nb2_multi = naive_bayes(x = X_train, y = y_train)
pred_nb2_multi = predict(mod_nb2_multi, X_test)
```

```{r}
#Alinear niveles y métricas
pred_nb2_multi = factor(pred_nb2_multi, levels = levels(y_train))
y_test = factor(y_test,  levels = levels(y_train))
cm_nv = confusionMatrix(pred_nb2_multi, y_test)   # data, reference
```

```{r}
cm_nv$table #matriz de confusión 
```

```{r}
cm_nv$overall["Accuracy"]
```

```{r}
precision = cm_nv$byClass[, "Pos Pred Value"] #precision
precision
```

```{r}
recall = cm_nv$byClass[, "Sensitivity"] #recall
recall
```

```{r}
f1 = 2 * precision * recall / (precision + recall) #f1 score
f1
```

```{r}
#matriz de confusión
cm$table
```

```{r}
cm$overall["Accuracy"] 
```

```{r}
precision = cm$byClass[, "Pos Pred Value"] #precision
precision
```

```{r}
recall = cm$byClass[, "Sensitivity"] #recall
recall
```

```{r}
f1 = 2 * precision * recall / (precision + recall) #f1 score
f1
```

# Y DE DOS CLASES
*✏️ La clasificación multiclase impone un mayor desafío, para facilitar las cosas dicotomizaremos el tipo de evento paranormal. Con ayuda de la función case_when() pueden recodificar el tipo de evento paranormal, por ejemplo, si es Haunted Places u Other.*

```{r}
#utilizamos misma partición y dicotomizamos sobre y_train y y_test 
#si se llama distinto a haunted places, que se llame Other
y_train_bin = case_when(
  str_detect(y_train, regex("Haunted Places", ignore_case = TRUE)) ~ "Haunted Places",
  TRUE ~ "Other")

y_test_bin = case_when(
  str_detect(y_test, regex("Haunted Places", ignore_case = TRUE)) ~ "Haunted Places",
  TRUE ~ "Other")

# Convertir a factor con niveles consistentes
y_train_bin = factor(y_train_bin, levels = c("Other", "Haunted Places"))
y_test_bin  = factor(y_test_bin,  levels = c("Other", "Haunted Places"))
```
*✏️ Vuelvan a entrenar un clasificador naïve Bayes con ambas funciones, ¿hubo alguna mejora?*

## e1071

```{r}
#  e1017
#entrenar
mod_nb_bin = naiveBayes(x = X_train, y = y_train_bin)
#predecir
pred_nb_bin = predict(mod_nb_bin, X_test)
#mismos niveles para métricas
pred_nb_bin = factor(pred_nb_bin, levels = levels(y_train_bin))
y_test_bin = factor(y_test_bin,    levels = levels(y_train_bin))
#resultados
cm_nb_bin = confusionMatrix(pred_nb_bin, y_test_bin)
cm_nb_bin$overall["Accuracy"]
```
```{r}
cm_nb_bin$table
```

## naive_bayes()

```{r}
# naive_bayes()
#entrenar
mod_nb2_bin = naive_bayes(x = X_train, y = y_train_bin)
#predecir
pred_nb2_bin = predict(mod_nb2_bin, X_test)
#Alinear niveles y métricas
pred_nb2_bin = factor(pred_nb2_bin, levels = levels(y_train_bin))
y_test_bin  = factor(y_test_bin,  levels = levels(y_train_bin))
#resultados
cm_nb2_bin = confusionMatrix(pred_nb2_bin, y_test_bin)   # data, reference
cm_nb2_bin$overall["Accuracy"]
```
```{r}
cm_nb2_bin$table
```
## naive_bayes() con use poisson 
*✏️ Un problema que enfrentan estas primeras implementaciones del clasificador naïve Bayes es el supuesto de la distribución normal para los nodos hijo. Este supuesto parece poco pertinente en este caso debido a que lo que contiene nuestra matriz de datos son en realidad conteos. La distribución Poisson resulta una mejor alternativa para este tipo de datos. Pueden utilizar esta distribución en la función naive_bayes() del paquete naivebayes mediante el argumento usepoisson = TRUE.*

```{r}
# naive_bayes()
#entrenar
mod_nb2_bin = naive_bayes(x = X_train, y = y_train_bin, usepoisson = TRUE)
#predecir
pred_nb2_bin   = predict(mod_nb2_bin, X_test)
#Alinear niveles y métricas
pred_nb2_bin = factor(pred_nb2_bin, levels = levels(y_train_bin))
y_test_bin = factor(y_test_bin,  levels = levels(y_train_bin))
#resultados
cm_nb2_bin  = confusionMatrix(pred_nb2_bin, y_test_bin)   # data, reference
cm_nb2_bin$overall["Accuracy"]
```
```{r}
cm_nb2_bin$table
```
